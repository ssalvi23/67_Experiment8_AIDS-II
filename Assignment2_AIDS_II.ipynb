{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXo9C8aUuffuzJyugkUPLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssalvi23/67_Experiment8_AIDS-II/blob/main/Assignment2_AIDS_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HXSmkrvqrZr4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "df = pd.read_csv('/content/StudentsPerformance (1).csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average score as the target variable\n",
        "df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
        "possible_categories = {\n",
        "    'gender': ['male', 'female'],\n",
        "    'race/ethnicity': ['group A', 'group B', 'group C', 'group D', 'group E'],\n",
        "    'parental level of education': ['some high school', 'high school', 'some college', 'associate\\'s degree', 'bachelor\\'s degree', 'master\\'s degree'],\n",
        "    'lunch': ['standard', 'free/reduced'],\n",
        "    'test preparation course': ['none', 'completed']\n",
        "}\n",
        "\n",
        "# Encode categorical features with the updated list of possible categories\n",
        "label_encoders = {}\n",
        "\n",
        "for feature, categories in possible_categories.items():\n",
        "    le = LabelEncoder()\n",
        "    le.fit(categories)\n",
        "    df[feature] = le.transform(df[feature])\n",
        "    label_encoders[feature] = le"
      ],
      "metadata": {
        "id": "tdYwwrGHt21W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the dataset into training and testing set**"
      ],
      "metadata": {
        "id": "fv1mkM-OvCcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target variable\n",
        "X = df.drop(['math score', 'reading score', 'writing score', 'average_score'], axis=1)\n",
        "y = df['average_score']\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ItAmtZumt2ws"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model building**"
      ],
      "metadata": {
        "id": "aWThrbI2vPge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCAAfYDGt2tX",
        "outputId": "c9c7d825-7206-40e4-f93e-8707316f2042"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and train the model**"
      ],
      "metadata": {
        "id": "6-_ZJ4QYvYHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-Y1YinNt2qR",
        "outputId": "6b313bd2-01fb-4b5f-8aeb-1dae4ee2e260"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4640.5112 - mae: 66.6468 - val_loss: 4348.7925 - val_mae: 64.3788\n",
            "Epoch 2/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4051.7222 - mae: 61.9326 - val_loss: 2846.7256 - val_mae: 51.2884\n",
            "Epoch 3/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2375.8225 - mae: 45.8706 - val_loss: 766.3217 - val_mae: 24.2141\n",
            "Epoch 4/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.5735 - mae: 20.3125 - val_loss: 202.1708 - val_mae: 11.5658\n",
            "Epoch 5/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.8501 - mae: 11.3201 - val_loss: 176.9358 - val_mae: 10.5362\n",
            "Epoch 6/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.4656 - mae: 10.7668 - val_loss: 174.0413 - val_mae: 10.4495\n",
            "Epoch 7/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.5352 - mae: 10.6024 - val_loss: 171.6242 - val_mae: 10.3553\n",
            "Epoch 8/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161.0272 - mae: 10.3102 - val_loss: 171.3008 - val_mae: 10.3081\n",
            "Epoch 9/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.0338 - mae: 10.7918 - val_loss: 168.9449 - val_mae: 10.2905\n",
            "Epoch 10/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166.3747 - mae: 10.5417 - val_loss: 167.7491 - val_mae: 10.2711\n",
            "Epoch 11/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.6308 - mae: 10.4118 - val_loss: 165.8640 - val_mae: 10.2127\n",
            "Epoch 12/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 158.1026 - mae: 10.1433 - val_loss: 167.0820 - val_mae: 10.1848\n",
            "Epoch 13/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.8757 - mae: 10.0843 - val_loss: 165.7417 - val_mae: 10.1964\n",
            "Epoch 14/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.1858 - mae: 10.4227 - val_loss: 164.4867 - val_mae: 10.1303\n",
            "Epoch 15/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 161.6933 - mae: 10.1763 - val_loss: 164.4612 - val_mae: 10.1252\n",
            "Epoch 16/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.0201 - mae: 10.0842 - val_loss: 164.1559 - val_mae: 10.1203\n",
            "Epoch 17/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 165.8309 - mae: 10.3215 - val_loss: 163.1472 - val_mae: 10.1044\n",
            "Epoch 18/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 151.0485 - mae: 10.0262 - val_loss: 163.9895 - val_mae: 10.1094\n",
            "Epoch 19/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 169.8182 - mae: 10.8409 - val_loss: 162.7713 - val_mae: 10.0612\n",
            "Epoch 20/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 153.9343 - mae: 10.1562 - val_loss: 162.9024 - val_mae: 10.0616\n",
            "Epoch 21/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 161.7527 - mae: 10.3706 - val_loss: 165.9232 - val_mae: 10.1160\n",
            "Epoch 22/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 164.8955 - mae: 10.5176 - val_loss: 162.5963 - val_mae: 10.0292\n",
            "Epoch 23/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 157.7944 - mae: 10.2281 - val_loss: 162.8167 - val_mae: 10.0397\n",
            "Epoch 24/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 148.8043 - mae: 10.0582 - val_loss: 162.0643 - val_mae: 10.0200\n",
            "Epoch 25/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 148.2271 - mae: 9.8752 - val_loss: 161.9993 - val_mae: 9.9832\n",
            "Epoch 26/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166.5560 - mae: 10.6173 - val_loss: 162.7652 - val_mae: 10.0263\n",
            "Epoch 27/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165.5419 - mae: 10.4380 - val_loss: 164.1125 - val_mae: 10.0460\n",
            "Epoch 28/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.5813 - mae: 10.5922 - val_loss: 162.6569 - val_mae: 10.0422\n",
            "Epoch 29/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.1058 - mae: 9.9227 - val_loss: 163.5053 - val_mae: 10.0049\n",
            "Epoch 30/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.1452 - mae: 9.9412 - val_loss: 162.4092 - val_mae: 9.9847\n",
            "Epoch 31/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148.0002 - mae: 9.8613 - val_loss: 161.4442 - val_mae: 9.9997\n",
            "Epoch 32/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162.3966 - mae: 10.2831 - val_loss: 161.9449 - val_mae: 9.9450\n",
            "Epoch 33/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151.1457 - mae: 9.9551 - val_loss: 164.4588 - val_mae: 10.0440\n",
            "Epoch 34/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.4500 - mae: 9.8577 - val_loss: 161.6940 - val_mae: 9.9890\n",
            "Epoch 35/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 153.4462 - mae: 10.1230 - val_loss: 161.0569 - val_mae: 9.9223\n",
            "Epoch 36/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.3998 - mae: 9.6775 - val_loss: 161.9981 - val_mae: 9.9954\n",
            "Epoch 37/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163.5251 - mae: 10.5452 - val_loss: 162.2083 - val_mae: 9.9906\n",
            "Epoch 38/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153.6217 - mae: 10.1918 - val_loss: 161.5014 - val_mae: 9.9756\n",
            "Epoch 39/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.8021 - mae: 9.9429 - val_loss: 162.7727 - val_mae: 10.0074\n",
            "Epoch 40/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.5692 - mae: 9.9806 - val_loss: 164.5938 - val_mae: 10.0282\n",
            "Epoch 41/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.0892 - mae: 10.4878 - val_loss: 162.0120 - val_mae: 9.9738\n",
            "Epoch 42/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.2176 - mae: 10.0435 - val_loss: 162.0932 - val_mae: 9.9982\n",
            "Epoch 43/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145.1224 - mae: 9.8825 - val_loss: 162.0350 - val_mae: 9.9578\n",
            "Epoch 44/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160.0781 - mae: 10.4229 - val_loss: 161.9068 - val_mae: 9.9849\n",
            "Epoch 45/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.2496 - mae: 9.7478 - val_loss: 162.2487 - val_mae: 9.9783\n",
            "Epoch 46/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.7013 - mae: 9.9929 - val_loss: 163.7812 - val_mae: 9.9857\n",
            "Epoch 47/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.6851 - mae: 10.1769 - val_loss: 163.3137 - val_mae: 9.9803\n",
            "Epoch 48/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.2559 - mae: 10.2440 - val_loss: 163.8133 - val_mae: 9.9867\n",
            "Epoch 49/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.2152 - mae: 10.2309 - val_loss: 163.2635 - val_mae: 9.9785\n",
            "Epoch 50/50\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.3621 - mae: 9.8311 - val_loss: 162.3066 - val_mae: 9.9901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cf615267c70>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error: {mae}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT4QXug7t2le",
        "outputId": "269e6f9c-521c-4a99-a225-2ee5a052db8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 216.2495 - mae: 11.4089  \n",
            "Mean Absolute Error: 11.194665908813477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model with a new student's data (example provided earlier)\n",
        "new_student = {\n",
        "    'gender': 'male',\n",
        "    'race/ethnicity': 'group B',\n",
        "    'parental level of education': 'some college',\n",
        "    'lunch': 'standard',\n",
        "    'test preparation course': 'completed'\n",
        "}\n",
        "\n",
        "new_student_df = pd.DataFrame([new_student])\n",
        "\n",
        "# Encode and standardize the new student data\n",
        "for feature in new_student_df.columns:\n",
        "    new_student_df[feature] = label_encoders[feature].transform(new_student_df[feature])\n",
        "\n",
        "new_student_scaled = scaler.transform(new_student_df)\n",
        "\n",
        "# Predict the score for the new student\n",
        "predicted_score = model.predict(new_student_scaled)\n",
        "print(f\"Predicted Average Score: {predicted_score[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaEvhtDNt2hp",
        "outputId": "184301b0-f132-4bed-edf3-67ff23beae3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "Predicted Average Score: 69.33409118652344\n"
          ]
        }
      ]
    }
  ]
}